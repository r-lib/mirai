---
title: "mirai - Reference Manual"
vignette: >
  %\VignetteIndexEntry{mirai - Reference Manual}
  %\VignetteEngine{litedown::vignette}
  %\VignetteEncoding{UTF-8}
---

```{r}
#| include: false
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  out.width = "100%"
)
set.seed(1234L)
```

This is a reference vignette of the package's core functionality.
Other package vignettes cover additional features.

### 1. Introduction

mirai (Japanese for 'future') implements the concept of *futures* in R.

Futures represent results from code that will complete later.
Code executes in a separate R process (*daemon*) and returns results to the main process (*host*).

#### mirai

`mirai()` creates a mirai object from an expression.

It returns immediately without blocking.
While the expression evaluates on a daemon, the host process continues working.

Expressions must be self-contained:

- Package functions must be namespaced with `::` or loaded via `library()` within the expression.
- Pass required functions, data, or objects explicitly via `...` or `.args`.

> This explicit design perfectly matches message-passing parallelism - attempting to infer global variables introduces unreliability, which we do not compromise on.

This example mimics an expensive calculation:

```{r}
#| label: exec
library(mirai)

m <- mirai(
  {
    Sys.sleep(time)
    rnorm(5L, mean)
  },
  time = 2L,
  mean = 4.5
)

m
m$data
unresolved(m)

# Do work whilst unresolved

m[]
m$data
```

A mirai is *unresolved* until its result is received, then *resolved*.
Use `unresolved()` to check its state.

Access results via `m$data` once resolved.
This will be the return value, or an 'errorValue' if the expression errored, crashed, or timed out (see [Error Handling](#error-handling)).

Use `m[]` to efficiently wait for and collect the value instead of repeatedly checking `unresolved(m)`.

You may also wait efficiently for mirai (or lists of mirai) to resolve using:

- `call_mirai()` returns when all the mirai passed to it have resolved.
- `race_mirai()` returns when the first mirai passed to it has resolved.

#### mirai (advanced)

For programmatic use, '.expr' accepts a pre-constructed language object and '.args' accepts a named list of arguments.
The following is equivalent:

```{r}
#| label: equiv
expr <- quote({Sys.sleep(time); rnorm(5L, mean)})
args <- list(time = 2L, mean = 4)

m1 <- mirai(.expr = expr, .args = args)
m1[]
```

This example performs an asynchronous write operation.
Passing `environment()` to '.args' conveniently provides all objects from the calling environment (like `x` and `file`):
```{r}
#| label: exec2
write.csv.async <- function(x, file) {
  mirai(write.csv(x, file), .args = environment())
}

m <- write.csv.async(x = rnorm(1e6), file = tempfile())

while (unresolved(m)) {
  cat("Writing file...\n")
  Sys.sleep(0.5) # or do other work
}
cat("Write complete:", is.null(m$data))
```

#### daemons

When writing a `mirai()` call, don't worry about where or how it executes.
End-users declare available resources using `daemons()`.

Without daemons configured, each `mirai()` call creates a new local background process (*ephemeral daemon*).

`daemons()` sets up persistent daemons to evaluate mirai expressions:

- Eliminates process startup overhead and limits concurrent processes.
- Cleanup between evaluations ensures each mirai remains self-contained.

See [local daemons](#local-daemons) for setup instructions.

### 2. Error Handling

Errors return as a character string with classes 'miraiError' and 'errorValue'.

Use `is_mirai_error()` to test for errors:
```{r}
#| label: errorexample
m1 <- mirai(stop("occurred with a custom message", call. = FALSE))
m1[]

m2 <- mirai(mirai::mirai())
m2[]

is_mirai_error(m2$data)
is_error_value(m2$data)
```

Error objects include `$stack.trace` for full stack traces and `$condition.class` for original condition classes:

```{r}
#| label: stackexample
f <- function(x) if (x > 0) stop("positive")

m3 <- mirai({f(-1); f(1)}, f = f)
m3[]

m3$data$stack.trace
m3$data$condition.class
```

Original error condition elements and `rlang::abort()` metadata are preserved:

```{r}
#| label: metaexample
f <- function(x) if (x > 0) stop("positive")

m4 <- mirai(rlang::abort("aborted", meta_uid = "UID001"))
m4[]

m4$data$meta_uid
```

User interrupts resolve to class 'miraiInterrupt' and 'errorValue'.
Use `is_mirai_interrupt()` to test for interrupts:
```{r}
#| label: interruptexample
m4 <- mirai(rlang::interrupt()) # simulates a user interrupt
is_mirai_interrupt(m4[])
```

Timeouts (via '.timeout') resolve to 'errorValue' of 5L, guarding against hanging processes:
```{r}
#| label: timeouts
m5 <- mirai(nanonext::msleep(1000), .timeout = 500)
m5[]

is_mirai_error(m5$data)
is_mirai_interrupt(m5$data)
is_error_value(m5$data)
```
`is_error_value()` tests for all mirai execution errors, user interrupts and timeouts.

### 3. Local Daemons

Daemons are persistent background processes that receive `mirai()` requests.

> Daemons inherit system configuration ('.Renviron', '.Rprofile') and load default packages.
To load only the base package (cutting startup time in half), set `R_SCRIPT_DEFAULT_PACKAGES=NULL` before launching.

Specify the number of daemons to launch:
```{r}
#| label: daemons
daemons(6)
```

Set `n` to one less than available cores for optimal performance.
Consider cores reserved for other purposes.

#### With Dispatcher (default)

The default `dispatcher = TRUE` creates a background dispatcher process that manages daemon connections.
Tasks dispatch efficiently in FIFO order, queueing at the dispatcher and sending to daemons as they become available.
The event-driven approach consumes no resources while waiting and stays synchronized with events.

`info()` provides current statistics as an integer vector:

- `connections`: currently active daemons
- `cumulative`: total daemons ever connected
- `awaiting`: tasks queued at dispatcher
- `executing`: tasks currently evaluating
- `completed`: tasks completed or cancelled

```{r}
#| label: info
info()
```

Set daemons to zero to reset.
This reverts to creating a new background process per request.

```{r}
#| label: daemons4
daemons(0)
```

#### Without Dispatcher

With `dispatcher = FALSE`, daemons connect directly to the host process:
```{r}
#| label: daemonsq
daemons(6, dispatcher = FALSE)
```
```{r}
#| label: daemonsq2
#| include: false
Sys.sleep(0.5)
```

Tasks send immediately in round-robin fashion, ensuring even distribution.
However, scheduling isn't optimal since task duration is unknown beforehand.
Tasks may queue behind long-running tasks while other daemons sit idle.

This resource-light approach suits similar-length tasks or when concurrent tasks don't exceed available daemons.

Info now shows 6 connections:
```{r}
#| label: daemonsqv
info()
```

#### everywhere()

`everywhere()` evaluates expressions on all daemons and persists state regardless of cleanup settings:
```{r}
#| label: everywhere
everywhere(library(DBI))
```
This keeps the [`DBI`](https://dbi.r-dbi.org/) package loaded.
You can also set up common resources like database connections:

```{r}
#| label: everywhere2
everywhere(con <<- dbConnect(RSQLite::SQLite(), file), file = tempfile())
```
Super-assignment makes 'con' available globally in all daemons:

```{r}
#| label: everywhere3
mirai(exists("con"))[]
```
Disconnect everywhere:

```{r}
#| label: everywhere4
everywhere(dbDisconnect(con))
```

> To evaluate in the global environment of each daemon (since mirai evaluations occur in an environment inheriting from global), use `evalq(envir = globalenv())`.
Example with `box::use()`:

```{r}
#| label: everywhere5
everywhere(
  evalq(
    box::use(dplyr[select], mirai[...]),
    envir = globalenv()
  )
)

daemons(0)
```

### 4. mirai_map

`mirai_map()` performs asynchronous parallel mapping over lists or vectors.

> Requires `daemons()` to be set (avoids launching too many ephemeral daemons).

#### Basic Usage

Returns immediately. Collect results with `x[]`:

```{r}
#| label: mmapbasic
with(daemons(3, seed = 1234L), mirai_map(1:3, rnorm, .args = list(mean = 20, sd = 2))[])
```

Use `.args` for constant arguments to `.f`, and `...` for objects referenced in `.f`:
```{r}
#| label: mmapargs
daemons(4, seed = 2345L)
fn <- function(x, range) runif(x, x, x + range)
ml <- mirai_map(c(a = 1, b = 2, c = 3), \(x) fn(x, x * 2), fn = fn)
ml
ml[]
```

#### Collecting Options

- `x[.flat]` flattens results (checks types to avoid coercion)
- `x[.progress]` shows progress bar (via cli) or text indicator
- `x[.stop]` applies early stopping, cancelling remaining tasks on first failure

```{r}
#| label: mmapcollect
#| error: true
mirai_map(list(a = 1, b = "a", c = 3), function(x) exp(x))[.stop]

mirai_map(c(0.1, 0.2, 0.3), Sys.sleep)[.progress, .flat]
```

#### Multiple Map

Dataframes and matrices map over **rows**.
`.f` must accept as many arguments as there are columns:

```{r}
#| label: mmapmulti
fruit <- c("melon", "grapes", "coconut")
df <- data.frame(i = seq_along(fruit), fruit = fruit)

mirai_map(df, sprintf, .args = list(fmt = "%d. %s"))[.flat]
```

Matrices also map over rows:
```{r}
#| label: mmapmatrix
mat <- matrix(1:4, nrow = 2L, dimnames = list(c("a", "b"), c("y", "z")))
mirai_map(mat, function(x = 10, y = 0, z = 0) x + y + z)[.flat]

daemons(0)
```

> To map over columns instead, use `as.list()` for dataframes or `t()` for matrices.

#### Nested Maps

For nested mapping, don't launch local daemons from within `mirai_map()`.
Instead:
```r
daemons(url = local_url())
launch_local(n)
```

### 5. Remote Infrastructure

This section covers setting up remote daemons, launching them on remote machines, and securing connections with TLS.

#### Remote Daemons Overview

Remote daemons run on network machines to process tasks remotely.

Call `daemons()` with a 'url' (e.g., 'tcp://10.75.32.70:5555') or use `host_url()` to construct one automatically.
The host listens on a single port for daemons to connect.

> IPv6 addresses are also supported and must be enclosed in square brackets `[]` to avoid confusion with the final colon separating the port.
For example, port 5555 on the IPv6 address `::ffff:a6f:50d` would be specified as `tcp://[::ffff:a6f:50d]:5555`.

Calling `host_url()` without a port uses '0', which automatically assigns a free ephemeral port:
```{r}
#| label: localqueue
daemons(url = host_url())
```
Query `launch_remote()` for the assigned port:
```{r}
#| label: remotev2
launch_remote()
```
Dynamically scale the number of daemons up or down as needed.

Reset all connections:
```{r}
#| label: reset2
daemons(0)
```
Closing connections exits all daemons.
With dispatcher, this exits the dispatcher first, then all connected daemons.

#### Launching Remote Daemons

> Launchers deploy daemons on remote machines.
Once deployed, daemons connect back to the host via TCP or TLS.

Local launchers run `Rscript` via a local shell.
Remote launchers run `Rscript` on remote machines.

Supply a remote launch configuration to the 'remote' argument of `daemons()` or `launch_remote()`.

Four configuration options:

1. `ssh_config()` for SSH access
2. `cluster_config()` for HPC resource managers (Slurm, SGE, Torque/PBS, LSF)
3. `http_config()` for HTTP API launch (e.g., Posit Workbench)
4. `remote_config()` for generic/custom launchers

All return simple lists that can be pre-constructed, saved, and reused.

#### SSH Direct Connection

Use for internal networks where the host can accept incoming connections.
Remote daemons connect back directly to the host port.

TLS is recommended for additional security.

Launch 4 daemons on 10.75.32.90 (SSH port 22 is default):
```{r}
#| label: ldmn
#| eval: false
daemons(
  n = 4,
  url = host_url(tls = TRUE, port = 5555),
  remote = ssh_config("ssh://10.75.32.90")
)
```
Launch one daemon on each machine using custom SSH port 222:
```{r}
#| label: ldmnd
#| eval: false
daemons(
  n = 1,
  url = host_url(tls = TRUE, port = 5555),
  remote = ssh_config(c("ssh://10.75.32.90:222", "ssh://10.75.32.91:222"))
)
```

#### SSH Tunnelling

Use SSH tunnelling when firewall policies prevent direct connections.
Requires SSH key-based authentication to be setup.

SSH tunnelling creates a tunnel after the initial SSH connection, using the same port on both host and daemon.

Supply a '127.0.0.1' URL to `daemons()`:

- `local_url(tcp = TRUE)` constructs this automatically
- Default wildcard port '0' assigns a free ephemeral port
- Specify a whitelisted port if the ephemeral port might be unavailable on daemons

With `local_url(tcp = TRUE, port = 5555)`, the host listens at `127.0.0.1:5555` and daemons dial into `127.0.0.1:5555` on their own machines.

Launch 2 daemons on 10.75.32.90 with tunnelling:
```{r}
#| label: sshrevtun
#| eval: false
daemons(
  n = 2,
  url = local_url(tcp = TRUE),
  remote = ssh_config("ssh://10.75.32.90", tunnel = TRUE)
)
```

#### HPC Cluster Resource Managers

`cluster_config()` deploys daemons via cluster resource managers.

Specify `command`:
- `"sbatch"` for Slurm
- `"qsub"` for SGE/Torque/PBS
- `"bsub"` for LSF

The `options` argument accepts scheduler options (lines typically preceded by `#`):
```
  Slurm: "#SBATCH --job-name=mirai
          #SBATCH --mem=10G
          #SBATCH --output=job.out"
  SGE: "#$ -N mirai
        #$ -l mem_free=10G
        #$ -o job.out"
  Torque/PBS: "#PBS -N mirai
               #PBS -l mem=10gb
               #PBS -o job.out"
  LSF: "#BSUB -J mirai
        #BSUB -M 10000
        #BSUB -o job.out"
```
- Pass as multi-line string (whitespace auto-handled) or use `\n` for newlines
- Include other shell commands (e.g., `cd` for working directory)
- Omit shebang lines (e.g., `#!/bin/bash`)
- Load environment modules if needed:
 
 ```
 module load R
 ```
 or for a specific R version:
 
 ```
 module load R/4.5.0
```

The `rscript` argument defaults to `"Rscript"` (assumes R is on PATH).
Specify full path if needed: `file.path(R.home("bin"), "Rscript")`.

##### Job Arrays

For many daemons, use job arrays instead of individual jobs.

Instead of:
```r
daemons(n = 100, url = host_url(), remote = cluster_config())
```
rather use:
```r
daemons(
  n = 1,
  url = host_url(),
  remote = cluster_config(options = "#SBATCH --array=1-100")
)
```

#### HTTP Launcher

`http_config()` launches daemons via HTTP API.

It takes the following arguments:

- `url`: API endpoint URL
- `method`: HTTP method (typically `"POST"`)
- `cookie`: session cookie for authentication
- `token`: bearer token for authentication
- `data`: request body containing a `"%s"` placeholder where the daemon launch command is inserted

Each argument accepts either a character value or a **function** returning a value.
When a function is supplied, it is called at launch time (when `launch_remote()` runs), not when the configuration is created.
This lazy evaluation ensures that dynamic values such as session cookies, API tokens, or endpoint URLs are always fresh at the moment of use.

##### Default: Posit Workbench

> Requires Posit Workbench 2026.01 or later, which supports authenticating the launcher using the session cookie.

By default, `http_config()` auto-configures for Posit Workbench.
The defaults for `url`, `cookie`, and `data` are functions (not function calls) that read Workbench environment information:

```r
http_config(
  url = posit_workbench_url,     # reads server address at launch time
  method = "POST",
  cookie = posit_workbench_cookie, # reads session cookie at launch time
  token = NULL,
  data = posit_workbench_data    # queries the compute environment at launch time
)
```

Because these are stored as functions, calling `http_config()` does no work â€” it simply saves the functions into the configuration list.
Only when daemons are actually launched are the functions evaluated, at which point the environment variables are read and the API is queried.
This means the configuration can be created early (e.g., at session start) while credentials that may change or expire are always obtained fresh.

Launch daemons in Posit Workbench:
```{r}
#| label: httpworkbench
#| eval: false
daemons(n = 2, url = host_url(), remote = http_config())
```

##### Custom HTTP APIs

For custom HTTP APIs, provide URL, authentication, and request body.
The `data` argument should include `"%s"` as a placeholder where the daemon launch command is inserted at launch time:
```{r}
#| label: httpcustom
#| eval: false
daemons(
  n = 2,
  url = host_url(),
  remote = http_config(
    url = "https://api.example.com/launch",
    method = "POST",
    token = function() Sys.getenv("MY_API_KEY"),
    data = '{"command": "%s"}'
  )
)
```

Here, `token` is a function so the API key environment variable is read each time daemons are launched.
The remaining arguments are plain character values used as-is.

##### Troubleshooting

`launch_remote()` with an `http_config()` configuration returns a list of server response data (invisibly).
Capture and inspect these to diagnose launch failures:
```{r}
#| label: httptrblsht
#| eval: false
daemons(url = host_url())
res <- launch_remote(remote = http_config())
```
Each element of `res` is the response for a single daemon launch request.

#### Generic Remote Configuration

`remote_config()` provides a generic framework for custom deployment commands.

The `args` argument must contain `"."`, which is replaced with the daemon launch command.

`cluster_config()` is easier for HPC, but `remote_config()` offers flexibility.
Slurm example:
``` r
daemons(
  n = 2,
  url = host_url(),
  remote = remote_config(
    command = "sbatch",
    args = c("--mem 512", "-n 1", "--wrap", "."),
    rscript = file.path(R.home("bin"), "Rscript"),
    quote = TRUE
  )
)
```

#### Manual Deployment

Call `launch_remote()` without 'remote' to get shell commands for manual deployment:
```{r}
#| label: launchremotereal
daemons(url = host_url())
launch_remote()
daemons(0)
```

#### TLS Secure Connections

TLS secures communications between host and remote daemons.

##### Automatic Zero-configuration Default

Use `tls+tcp://` scheme or `host_url(tls = TRUE)`:
```{r}
#| label: tlsremote
daemons(url = host_url(tls = TRUE))
```
Keys and certificates generate automatically.
Private keys remain on the host.

Self-signed certificates are included in `launch_remote()` commands:
```{r}
#| label: launch_remote
launch_remote(1)
```
```{r}
#| label: tlsclose
daemons(0)
```

##### CA Signed Certificates

Alternatively, generate certificates via a Certificate Signing Request (CSR) to a Certificate Authority (public or internal).

1. Generate a private key and CSR:
  - using Mbed TLS: <https://mbed-tls.readthedocs.io/en/latest/kb/how-to/generate-a-certificate-request-csr/>
  - using OpenSSL: <https://www.feistyduck.com/library/openssl-cookbook/online/> (Chapter 1.2 Key and Certificate Management)

2. Provide the generated CSR to the CA for it to sign a new TLS certificate.
  - The common name (CN) of the certificate must be identical to the hostname or IP address actually used for the connection. As this is verified, it will fail if not the same.
  - The received certificate should comprise a block of cipher text between the markers `-----BEGIN CERTIFICATE-----` and `-----END CERTIFICATE-----`. Make sure to request the certificate in the PEM format. If only available in other formats, the TLS library used should usually provide conversion utilities.
  - Check also that the private key is a block of cipher text between the markers `-----BEGIN PRIVATE KEY-----` and `-----END PRIVATE KEY-----`.

3. When setting daemons, the TLS certificate and private key should be provided to the 'tls' argument of `daemons()`.
  - If the certificate and private key have been imported as character strings `cert` and `key` respectively, then the 'tls' argument may be specified as the character vector `c(cert, key)`.
  - Alternatively, the certificate may be copied to a new text file, with the private key appended, in which case the path/filename of this file may be provided to the 'tls' argument.

4. The certificate chain to the CA should be supplied to the 'tlscert' argument of `daemons()`.
  - The certificate chain should comprise multiple certificates, each between `-----BEGIN CERTIFICATE-----` and `-----END CERTIFICATE-----` markers. The first one should be the newly-generated TLS certificate, the same supplied to `daemons()`, and the final one should be a CA root certificate.
  - These are the only certificates required if the certificate was signed directly by a CA. If not, then the intermediate certificates should be included in a certificate chain that starts with the TLS certificate and ends with the certificate of the CA.
  - If these are concatenated together as a single character string `certchain`, then the character vector comprising this and an empty character string `c(certchain, "")` may be supplied to 'tlscert'.
  - Alternatively, if these are written to a file (and the file replicated on the remote machines), then the 'tlscert' argument may also be specified as a path/filename (assuming these are the same on each machine).

### 6. Compute Profiles

The `.compute` argument to `daemons()` creates separate, independent daemon pools (*compute profiles*) for heterogeneous compute requirements:

- Target daemons with specific specs (CPUs, memory, GPU, accelerators)
- Split between local and remote computation

Pass a character string to `.compute` as the profile name (`NULL` defaults to 'default').
Settings save under this name.

Specify `.compute` in `mirai()` to use a profile (`NULL` uses 'default').

Other functions (`info()`, `launch_local()`, `launch_remote()`) also accept `.compute`.

#### `with_daemons()` and `local_daemons()`

`with_daemons()` or `local_daemons()` with a profile name sets the default for all functions within that scope:

```{r}
#| label: withdaemons
daemons(1, .compute = "cpu")
daemons(1, .compute = "gpu")

with_daemons("cpu", {
  m1 <- mirai(Sys.getpid())
})

with_daemons("gpu", {
  m2 <- mirai(Sys.getpid())
  m3 <- mirai(Sys.getpid(), .compute = "cpu")
  local_daemons("cpu")
  m4 <- mirai(Sys.getpid())
})

m1[]
m2[] # different to m1

m3[] # same as m1
m4[] # same as m1

with_daemons("cpu", daemons(0))
with_daemons("gpu", daemons(0))
```

#### With Method

The `with()` method creates daemons for an expression's duration, then automatically resets them.
Functions within the scope use the daemons' compute profile.

Designed for running Shiny apps with specific daemon counts:

```{r}
#| label: withshiny
#| eval: false
with(daemons(4), shiny::runApp(app))
# Or:
with(daemons(4, .compute = "shiny"), shiny::runApp(app))
```

> Note: The app must already be created.
Don't wrap `shiny::shinyApp()` since `runApp()` is called when printed, after `with()` returns.

Shiny apps execute all mirai calls before returning (blocking).
For other expressions, collect all mirai values to ensure completion before daemon reset.

### 7. Advanced Topics

#### Random Number Generation

mirai uses L'Ecuyer-CMRG streams (like base R's parallel package) for statistically-sound parallel RNG.

Streams divide the RNG sequence at far-apart intervals that don't overlap, ensuring valid parallel results.

**Default (`seed = NULL`)**: New stream per daemon (like base R):

- Statistically sound but not numerically reproducible across runs
- Different daemon counts send tasks to different daemons
- Dispatcher sends tasks dynamically (not guaranteed same daemon each run)

**Reproducible (`seed = integer`)**: New stream per `mirai()` call (not per daemon):

- Deterministic, reproducible results
- Regardless of daemon count
- Negligible performance impact

#### Synchronous Mode

`daemons(sync = TRUE)` enables synchronous mode.
Mirai evaluate immediately without async operation, useful for testing and debugging with `browser()`.

Restrict to a specific profile by specifying `.compute`.
Only `seed` affects behavior with `sync = TRUE`.

Example usage:

```{r}
#| label: syncdaemons
# run everything in sync:
daemons(sync = TRUE)
mp <- mirai_map(1:2, \(x) Sys.getpid())
daemons(0)
mp[]


# Use sync with the 'sync' compute profile:
daemons(sync = TRUE, .compute = "sync")
with_daemons("sync", {
  mp <- mirai_map(1:2, \(x) Sys.getpid())
})
daemons(0, .compute = "sync")
mp[]
```
