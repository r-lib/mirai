---
title: "mirai - Torch Integration"
vignette: >
  %\VignetteIndexEntry{mirai - Torch Integration}
  %\VignetteEngine{litedown::vignette}
  %\VignetteEncoding{UTF-8}
---


### Torch Integration

Custom serialization functions may be registered to handle external pointer type reference objects.

This allows tensors from the [`torch`](https://torch.mlverse.org/) package to be used seamlessly in 'mirai' computations.

#### Setup Steps

1. Create the serialization configuration, specifying 'class' as 'torch_tensor'.
1. Set up daemons, supplying the configuration to the 'serial' argument.
1. (Optional) Use `everywhere()` to make the `torch` package available on all daemons for convenience.


``` r
library(mirai)
library(torch)

cfg <- serial_config(
  class = "torch_tensor",
  sfunc = torch::torch_serialize,
  ufunc = torch::torch_load
)

daemons(1, serial = cfg)
#> [1] 1

everywhere(library(torch))
```
#### Example Usage

The below example creates a convolutional neural network using `torch::nn_module()`.

A set of model parameters is also specified.

The model specification and parameters are then passed to and initialized within a 'mirai'.


``` r
model <- nn_module(
  initialize = function(in_size, out_size) {
    self$conv1 <- nn_conv2d(in_size, out_size, 5)
    self$conv2 <- nn_conv2d(in_size, out_size, 5)
  },
  forward = function(x) {
    x <- self$conv1(x)
    x <- nnf_relu(x)
    x <- self$conv2(x)
    x <- nnf_relu(x)
    x
  }
)

params <- list(in_size = 1, out_size = 20)

m <- mirai(do.call(model, params), model = model, params = params)

m[]
#> An `nn_module` containing 1,040 parameters.
#> 
#> ── Modules ───────────────────────────────────────────────────────────────────────────────────────────────────────
#> • conv1: <nn_conv2d> #520 parameters
#> • conv2: <nn_conv2d> #520 parameters
```
The returned model is an object containing many tensor elements.

``` r
m$data$parameters$conv1.weight
#> torch_tensor
#> (1,1,.,.) = 
#>   0.0189 -0.1506  0.0023  0.1501 -0.1757
#>   0.0669  0.1206  0.0427 -0.0692 -0.1349
#>  -0.0065 -0.0556 -0.0857  0.0048  0.0862
#>   0.1897  0.0019 -0.1310 -0.1794 -0.0409
#>   0.1583 -0.0258 -0.0067 -0.0810  0.1182
#> 
#> (2,1,.,.) = 
#>   0.0262 -0.0232 -0.0513  0.1181  0.0831
#>   0.1551  0.0901  0.1161  0.0168 -0.0372
#>   0.1400 -0.1008 -0.1285  0.0256 -0.0831
#>   0.0687 -0.1620 -0.1690 -0.1126 -0.0406
#>  -0.1019 -0.0887 -0.1805  0.1355  0.1608
#> 
#> (3,1,.,.) = 
#>   0.0861  0.1421  0.0784  0.1231  0.0367
#>   0.1372  0.0882  0.0409  0.0859  0.0878
#>  -0.0310 -0.1844  0.0546  0.1130  0.1927
#>   0.1482  0.1607  0.0243 -0.1358  0.1823
#>  -0.0085  0.1374  0.0963 -0.1537  0.0415
#> 
#> (4,1,.,.) = 
#>  -0.0550  0.1675 -0.1112 -0.0962  0.0674
#>  -0.1366 -0.1604 -0.0022  0.0933  0.0907
#>   0.0208  0.1882 -0.0011 -0.1908 -0.1540
#>  -0.1022 -0.1659  0.0245  0.0262  0.0059
#>  -0.1806  0.0408 -0.0881 -0.1467 -0.1563
#> 
#> (5,1,.,.) = 
#>   0.0079 -0.0660  0.1558  0.0976  0.0000
#> ... [the output was truncated (use n=-1 to disable)]
#> [ CPUFloatType{20,1,5,5} ][ requires_grad = TRUE ]
```
It is usual for model parameters to then be passed to an optimiser.

This can also be initialized within a 'mirai' process.

``` r
optim <- mirai(optim_rmsprop(params = params), params = m$data$parameters)

optim[]
#> <optim_rmsprop>
#>   Inherits from: <torch_optimizer>
#>   Public:
#>     add_param_group: function (param_group) 
#>     clone: function (deep = FALSE) 
#>     defaults: list
#>     initialize: function (params, lr = 0.01, alpha = 0.99, eps = 1e-08, weight_decay = 0, 
#>     load_state_dict: function (state_dict, ..., .refer_to_state_dict = FALSE) 
#>     param_groups: list
#>     state: State, R6
#>     state_dict: function () 
#>     step: function (closure = NULL) 
#>     zero_grad: function (set_to_none = FALSE) 
#>   Private:
#>     deep_clone: function (name, value) 
#>     step_helper: function (closure, loop_fun)

daemons(0)
#> [1] 0
```
Above, tensors and complex objects containing tensors were passed seamlessly between host and daemon processes, in the same way as any other R object.

The custom serialization in `mirai` leverages R's own native 'refhook' mechanism to allow such completely transparent usage. Designed to be fast and efficient, data copies are minimised and the 'official' serialization methods from the `torch` package are used directly.
